{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T13:16:02.793284Z",
     "start_time": "2025-03-15T13:16:01.493279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import yaml\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from src import data_preprocessing as dp\n",
    "from src import data_augmentation as da\n",
    "from src import feature_extraction as fe"
   ],
   "id": "bc6c5e0b999c1c05",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T13:16:02.809199Z",
     "start_time": "2025-03-15T13:16:02.797993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load configuration\n",
    "with open(\"config/config.yaml\", 'r') as ymlfile:\n",
    "    cfg = yaml.safe_load(ymlfile)\n",
    "\n",
    "raw_dirs = cfg[\"data\"][\"raw\"]\n",
    "processed_dirs = cfg[\"data\"][\"processed\"]\n",
    "resize_size = tuple(cfg[\"preprocessing\"][\"resize_size\"])\n",
    "threshold = cfg[\"preprocessing\"][\"threshold\"]\n",
    "classes = cfg[\"classes\"]\n",
    "augment = cfg[\"augmentation\"][\"augment\"]\n",
    "rotation_range = cfg[\"augmentation\"][\"rotation_range\"]\n",
    "shift_range = cfg[\"augmentation\"][\"shift_range\"]\n",
    "flip_h = cfg[\"augmentation\"][\"flip_h\"]\n",
    "flip_v = cfg[\"augmentation\"][\"flip_v\"]\n",
    "noise_stddev = cfg[\"augmentation\"][\"noise_stddev\"]\n",
    "method = cfg[\"feature_extraction\"][\"method\"]\n",
    "\n",
    "# Create dirs\n",
    "for processed_dir in processed_dirs:\n",
    "    for class_name in classes:\n",
    "        path = os.path.join(processed_dir, class_name)\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# Calculate total images\n",
    "train_imgs = sum(\n",
    "    len(os.listdir(os.path.join(raw_dirs[0], class_name)))\n",
    "    for class_name in classes\n",
    ")\n",
    "test_imgs = sum(\n",
    "    len(os.listdir(os.path.join(raw_dirs[1], class_name)))\n",
    "    for class_name in classes\n",
    ")\n",
    "total_imgs = train_imgs + test_imgs"
   ],
   "id": "a1191c057dd8b5c4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T13:16:09.113547Z",
     "start_time": "2025-03-15T13:16:02.903943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Process the images\n",
    "progress_bar = tqdm(total=total_imgs, desc=\"Processing images\", unit=\"image\")\n",
    "\n",
    "for raw_dir, processed_dir in zip(raw_dirs, processed_dirs):\n",
    "    for class_name in classes:\n",
    "        in_class_dir = os.path.join(raw_dir, class_name)\n",
    "        out_class_dir = os.path.join(processed_dir, class_name)\n",
    "\n",
    "        for file in os.listdir(in_class_dir):\n",
    "            in_file_path = os.path.join(in_class_dir, file)\n",
    "            image = cv2.imread(in_file_path, cv2.IMREAD_GRAYSCALE)\n",
    "            processed_image = dp.preprocess_image(\n",
    "                image,\n",
    "                resize_size,\n",
    "                threshold\n",
    "            )\n",
    "            out_file_path = os.path.join(out_class_dir, file)\n",
    "            cv2.imwrite(out_file_path, processed_image)\n",
    "            progress_bar.update(1)\n",
    "\n",
    "progress_bar.close()"
   ],
   "id": "e1284f7cea45dce5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 5266/5266 [00:06<00:00, 848.94image/s] \n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T13:16:09.124903Z",
     "start_time": "2025-03-15T13:16:09.121442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Augment the training images\n",
    "if augment:\n",
    "    progress_bar = tqdm(total=train_imgs, desc=\"Augmenting images\", unit=\"image\")\n",
    "    for class_name in classes:\n",
    "        in_class_dir = os.path.join(processed_dirs[0], class_name)\n",
    "\n",
    "        for file in os.listdir(in_class_dir):\n",
    "            in_file_path = os.path.join(in_class_dir, file)\n",
    "            image = cv2.imread(in_file_path, cv2.IMREAD_GRAYSCALE)\n",
    "            image = image.astype(np.float32) / 255.0\n",
    "            augmented_image = da.augment_image(\n",
    "                image,\n",
    "                rotation_range,\n",
    "                shift_range,\n",
    "                flip_h,\n",
    "                flip_v,\n",
    "                noise_stddev\n",
    "            )\n",
    "            augmented_image = (augmented_image * 255).astype(np.uint8)\n",
    "            out_file_path = os.path.join(in_class_dir, file)\n",
    "            cv2.imwrite(out_file_path, augmented_image)\n",
    "            progress_bar.update(1)\n",
    "progress_bar.close()"
   ],
   "id": "69b117841243e533",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T13:16:14.437335Z",
     "start_time": "2025-03-15T13:16:09.163981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract features\n",
    "all_features = []\n",
    "all_labels = []\n",
    "all_image_paths = []\n",
    "\n",
    "if method == 'sift':\n",
    "    total_imgs = total_imgs * 2\n",
    "progress_bar = tqdm(total=total_imgs, desc=\"Processing features\", unit=\"features\")\n",
    "\n",
    "for processed_dir in processed_dirs:\n",
    "    for class_name in classes:\n",
    "        in_class_dir = os.path.join(processed_dir, class_name)\n",
    "        features, image_paths = fe.extract_features(\n",
    "            in_class_dir,\n",
    "            method,\n",
    "            cfg[\"feature_extraction\"],\n",
    "            progress_bar\n",
    "        )\n",
    "\n",
    "        all_features.append(features)\n",
    "        all_labels.extend([class_name] * features.shape[0])\n",
    "        all_image_paths.extend(image_paths)\n",
    "\n",
    "progress_bar.close()\n",
    "\n",
    "all_features = np.vstack(all_features)\n",
    "data_dict = {\n",
    "    \"features\": all_features,\n",
    "    \"labels\": all_labels,\n",
    "    \"image_paths\": all_image_paths\n",
    "}\n",
    "\n",
    "with open(\"results/features.pkl\", \"wb\") as f:\n",
    "    print(\"Saving pickle file...\")\n",
    "    pickle.dump(data_dict, f)\n",
    "    print(\"Done!\")"
   ],
   "id": "c13f2ca63a945406",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing features:   3%|▎         | 145/5266 [00:04<02:52, 29.69features/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 13\u001B[39m\n\u001B[32m     11\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m class_name \u001B[38;5;129;01min\u001B[39;00m classes:\n\u001B[32m     12\u001B[39m     in_class_dir = os.path.join(processed_dir, class_name)\n\u001B[32m---> \u001B[39m\u001B[32m13\u001B[39m     features, image_paths = \u001B[43mfe\u001B[49m\u001B[43m.\u001B[49m\u001B[43mextract_features\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     14\u001B[39m \u001B[43m        \u001B[49m\u001B[43min_class_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     15\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     16\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcfg\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfeature_extraction\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     17\u001B[39m \u001B[43m        \u001B[49m\u001B[43mprogress_bar\u001B[49m\n\u001B[32m     18\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     20\u001B[39m     all_features.append(features)\n\u001B[32m     21\u001B[39m     all_labels.extend([class_name] * features.shape[\u001B[32m0\u001B[39m])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Code/School/IKT52/Project/src/feature_extraction.py:166\u001B[39m, in \u001B[36mextract_features\u001B[39m\u001B[34m(path, method, config, progress_bar)\u001B[39m\n\u001B[32m    164\u001B[39m     feat = extract_gabor_features(image, config[\u001B[33m'\u001B[39m\u001B[33mgabor\u001B[39m\u001B[33m'\u001B[39m])\n\u001B[32m    165\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m method == \u001B[33m'\u001B[39m\u001B[33mglcm\u001B[39m\u001B[33m'\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m166\u001B[39m     feat = \u001B[43mextract_glcm_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mglcm\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    167\u001B[39m features_list.append(feat)\n\u001B[32m    168\u001B[39m image_paths.append(filepath)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Code/School/IKT52/Project/src/feature_extraction.py:88\u001B[39m, in \u001B[36mextract_glcm_features\u001B[39m\u001B[34m(image, glcm_config)\u001B[39m\n\u001B[32m     86\u001B[39m feats = []\n\u001B[32m     87\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m prop \u001B[38;5;129;01min\u001B[39;00m properties:\n\u001B[32m---> \u001B[39m\u001B[32m88\u001B[39m     feat = \u001B[43mgraycoprops\u001B[49m\u001B[43m(\u001B[49m\u001B[43mglcm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     89\u001B[39m     feats.append(feat.mean())\n\u001B[32m     90\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m np.array(feats)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Code/School/IKT52/Project/.venv/lib/python3.12/site-packages/skimage/feature/texture.py:312\u001B[39m, in \u001B[36mgraycoprops\u001B[39m\u001B[34m(P, prop)\u001B[39m\n\u001B[32m    310\u001B[39m     results[mask_1] = cov[mask_1] / (std_i[mask_1] * std_j[mask_1])\n\u001B[32m    311\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m prop \u001B[38;5;129;01min\u001B[39;00m [\u001B[33m'\u001B[39m\u001B[33mcontrast\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mdissimilarity\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mhomogeneity\u001B[39m\u001B[33m'\u001B[39m]:\n\u001B[32m--> \u001B[39m\u001B[32m312\u001B[39m     weights = \u001B[43mweights\u001B[49m\u001B[43m.\u001B[49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_level\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_level\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    313\u001B[39m     results = np.sum(P * weights, axis=(\u001B[32m0\u001B[39m, \u001B[32m1\u001B[39m))\n\u001B[32m    315\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m results\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the features from the pickle file\n",
    "with open(\"results/features.pkl\", \"rb\") as f:\n",
    "    data_dict = pickle.load(f)\n",
    "\n",
    "features = data_dict[\"features\"]\n",
    "labels = data_dict[\"labels\"]\n",
    "\n",
    "# Reduce the features to 2 dimensions using PCA\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "features_2d = pca.fit_transform(features)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "for class_name in classes:\n",
    "    indices = [i for i, label in enumerate(labels) if label == class_name]\n",
    "    plt.scatter(\n",
    "        features_2d[indices, 0],\n",
    "        features_2d[indices, 1],\n",
    "        label=class_name,\n",
    "        alpha=0.5,\n",
    "        s=3\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.title(\"2D Visualization of Extracted Features (PCA)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "12ecc2b19edf4792",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
